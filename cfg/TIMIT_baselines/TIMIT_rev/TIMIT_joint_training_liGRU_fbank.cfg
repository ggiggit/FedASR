[cfg_proto]
cfg_proto = proto/global.proto
cfg_proto_chunk = proto/global_chunk.proto

[exp]
cmd = 
run_nn_script = run_nn.py
out_folder = exp/TIMIT_joint_training_liGRU_fbank
seed = 1234
use_cuda = True
multi_gpu = False
save_gpumem = False
n_epochs_tr = 24

[dataset1]
data_name = TIMIT_tr
fea =fea_name=fbankclean
     fea_lst=quick_test/data/train/feats_fbank.scp
     fea_opts=apply-cmvn --utt2spk=ark:quick_test/data/train/utt2spk  ark:quick_test/fbank/cmvn_train.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
     cw_left=0
     cw_right=0


    fea_name=fbankrev
	fea_lst=/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/train/feats.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/train/utt2spk  scp:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/train/cmvn.scp ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0
	
lab = lab_name=lab_cd
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=quick_test/data/train/
	lab_graph=quick_test/graph
	
	lab_name=lab_mono
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=quick_test/data/train/
	lab_graph=quick_test/graph	
n_chunks = 5

[dataset2]
data_name = TIMIT_dev
fea = fea_name=fbankclean
      fea_lst=quick_test/data/dev/feats_fbank.scp
      fea_opts=apply-cmvn --utt2spk=ark:quick_test/data/dev/utt2spk  ark:quick_test/fbank/cmvn_dev.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
      cw_left=0
      cw_right=0


    fea_name=fbankrev
	fea_lst=/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/dev/feats.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/data/dev/utt2spk  scp:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/dev/cmvn_fbank.scp  ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0

lab = lab_name=lab_cd
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali_dev
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=quick_test/data/dev/
	lab_graph=quick_test/graph
	
	lab_name=lab_mono
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali_dev
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=quick_test/data/dev/
	lab_graph=quick_test/graph

n_chunks = 1

[dataset3]
data_name = TIMIT_test
fea =   fea_name=fbankclean
	fea_lst=quick_test/data/test/feats_fbank.scp
	fea_opts=apply-cmvn --utt2spk=ark:quick_test/data/test/utt2spk  ark:quick_test/fbank/cmvn_test.ark ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0


        fea_name=fbankrev
	fea_lst=/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/test/feats.scp
	fea_opts=apply-cmvn --utt2spk=ark:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/test/utt2spk  scp:/home/mirco/kaldi-trunk/egs/timit_rev/s5/data/test/cmvn_fbank.scp  ark:- ark:- | add-deltas --delta-order=0 ark:- ark:- |
	cw_left=0
	cw_right=0

lab = lab_name=lab_cd
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali_test
	lab_opts=ali-to-pdf
	lab_count_file=auto
	lab_data_folder=quick_test/data/test/
	lab_graph=quick_test/graph
	
	lab_name=lab_mono
	lab_folder=quick_test/dnn4_pretrain-dbn_dnn_ali_test
	lab_opts=ali-to-phones --per-frame=true
	lab_count_file=none
	lab_data_folder=quick_test/data/test/
	lab_graph=quick_test/graph

n_chunks = 1



[data_use]
train_with = TIMIT_tr
valid_with = TIMIT_dev
forward_with = TIMIT_test

[batches]
batch_size_train = 8
max_seq_length_train = 1000
increase_seq_length_train = True
start_seq_len_train = 100
multply_factor_seq_len_train = 2
batch_size_valid = 8
max_seq_length_valid = 1000

[architecture1]
arch_name = liGRU_SE
arch_proto = proto/liGRU.proto
arch_library = neural_networks
arch_class = liGRU
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = True
ligru_lay = 550,550,550
ligru_drop = 0.2,0.2,0.2
ligru_use_laynorm_inp = False
ligru_use_batchnorm_inp = False
ligru_use_laynorm = False,False,False
ligru_use_batchnorm = True,True,True
ligru_bidir = True
ligru_act = relu,relu,relu
ligru_orthinit = True
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture2]
arch_name = MLP_SE
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = 40
dnn_drop = 0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = False
dnn_use_laynorm = False
dnn_act = linear
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture3]
arch_name = liGRU_SR
arch_proto = proto/liGRU.proto
arch_library = neural_networks
arch_class = liGRU
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = True
ligru_lay = 550,550,550,550
ligru_drop = 0.2,0.2,0.2,0.2
ligru_use_laynorm_inp = False
ligru_use_batchnorm_inp = False
ligru_use_laynorm = False,False,False,False
ligru_use_batchnorm = True,True,True,True
ligru_bidir = True
ligru_act = relu,relu,relu,relu
ligru_orthinit = True
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture4]
arch_name = MLP_layers
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = N_out_lab_cd
dnn_drop = 0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = False
dnn_use_laynorm = False
dnn_act = softmax
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[architecture5]
arch_name = MLP_layers2
arch_proto = proto/MLP.proto
arch_library = neural_networks
arch_class = MLP
arch_pretrain_file = none
arch_freeze = False
arch_seq_model = False
dnn_lay = 48
dnn_drop = 0.0
dnn_use_laynorm_inp = False
dnn_use_batchnorm_inp = False
dnn_use_batchnorm = False
dnn_use_laynorm = False
dnn_act = softmax
arch_lr = 0.0004
arch_halving_factor = 0.5
arch_improvement_threshold = 0.001
arch_opt = rmsprop
opt_momentum = 0.0
opt_alpha = 0.95
opt_eps = 1e-8
opt_centered = False
opt_weight_decay = 0.0

[model]
model_proto = proto/model.proto
model = out_dnn1=compute(liGRU_SE,fbankrev)
        out_dnn_SE=compute(MLP_SE,out_dnn1)
        out_dnn2=compute(liGRU_SR,out_dnn_SE)
	    out_dnn3=compute(MLP_layers,out_dnn2)
	    out_dnn4=compute(MLP_layers2,out_dnn2)
	    loss_mono=cost_nll(out_dnn4,lab_mono)
	    loss_mono_w=mult_constant(loss_mono,1.0)
        loss_se=mse(out_dnn_SE,fbankclean)
        loss_se_w=mult_constant(loss_se,1.0)
	    loss_cd=cost_nll(out_dnn3,lab_cd)
	    loss_sum1=sum(loss_cd,loss_mono_w)
        loss_final=sum(loss_sum1,loss_se_w)
	    err_final=cost_err(out_dnn3,lab_cd)

[forward]
forward_out = out_dnn3
normalize_posteriors = True
normalize_with_counts_from = lab_cd
save_out_file = True
require_decoding = True

[decoding]
decoding_script_folder = kaldi_decoding_scripts/
decoding_script = decode_dnn.sh
decoding_proto = proto/decoding.proto
min_active = 200
max_active = 7000
max_mem = 50000000
beam = 13.0
latbeam = 8.0
acwt = 0.2
max_arcs = -1
skip_scoring = false
scoring_script = local/score.sh
scoring_opts = "--min-lmwt 1 --max-lmwt 10"
norm_vars = False

